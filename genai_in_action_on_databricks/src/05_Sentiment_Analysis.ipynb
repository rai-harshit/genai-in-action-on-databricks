{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d649c8fc-3f07-4f06-83f0-f282a3b4d917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: openai in /databricks/python3/lib/python3.10/site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.54.4-py3-none-any.whl (389 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 389.6/389.6 kB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.4/76.4 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<5,>=4.11\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /databricks/python3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.10/site-packages (from openai) (1.10.6)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 325.2/325.2 kB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.0/78.0 kB 9.0 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 6.7 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, jiter, h11, httpcore, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-8d65db29-6d9c-43fd-b82c-72b63471243f\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Not uninstalling openai at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-8d65db29-6d9c-43fd-b82c-72b63471243f\n",
      "    Can't uninstall 'openai'. No files were found to uninstall.\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.7.1 openai-1.54.4 typing-extensions-4.12.2\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee7aee98-8046-470a-a3d8-f19f907daa50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2eb6191-b86c-41a3-8314-d31819d4b452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbac110-5ec6-4895-9b90-ab703d697dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### PERFORM TEXT TRANSLATION\n",
    "DATABRICKS_TOKEN = DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "def perform_sentiment_analysis(review):\n",
    "  # How to get your Databricks token: https://docs.databricks.com/en/dev-tools/auth/pat.html\n",
    "  # DATABRICKS_TOKEN = os.environ.get('DATABRICKS_TOKEN')\n",
    "  # Alternatively in a Databricks notebook you can use this:\n",
    "  client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"<link-to-the-databricks-model-serving-endpoint>\"\n",
    "  )\n",
    "\n",
    "  chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"I sell cameras all around the world. My customers have left a feedback. Rate each feedback from 1 to 5- 1 being very negative and 5 being very positive. Also, mention if the review is positive (represented by 1) or negative (represented by -1) or neutral (represented by 0). Also, extract the key highlights of the review within 25 words as a summary. Make sure it contains the key complalins or praises from the review. Your output should be of the format rating|sentiment|summary. Example: 4|1|This is a great camera. Absolutely do not saying anything else. Here is the review:\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": f\"{review}. Remember, don't use any other filler words. Your response must strictly be of the format rating|sentiment|summary.\"\n",
    "    }\n",
    "    ],\n",
    "    model=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "    max_tokens=200\n",
    "  )\n",
    "  print(\"Sending request to Llama 3.1\")\n",
    "  return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "083a7e20-7500-4098-88b9-f7101d354ec6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, split, col\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "# Register the translate_review function as a UDF\n",
    "sentiment_analysis_udf = udf(perform_sentiment_analysis, StringType())\n",
    "\n",
    "df_translated = spark.read.table(\"harshit_rai_genai_demo.products.camera_all_reviews_translated\")\n",
    "\n",
    "df_translated = df_translated.withColumn(\"raw_sentiment\", sentiment_analysis_udf(df_translated.translated_review))\n",
    "df_translated = df_translated.withColumn(\"rating\", split(df_translated.raw_sentiment, \"\\|\")[0]).withColumn(\"sentiment\", split(df_translated.raw_sentiment, \"\\|\")[1]).withColumn(\"summary\", split(df_translated.raw_sentiment, \"\\|\")[2])\n",
    "df_translated = df_translated.withColumn(\"rating\", col(\"rating\").cast(IntegerType())).withColumn(\"sentiment\", col(\"sentiment\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04630d3a-8838-4f1b-a2f2-314cb7bee84f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_translated.write.mode(\"overwrite\").saveAsTable(\"harshit_rai_genai_demo.products.camera_reviews_with_sentiment_analysis\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Sentiment_Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
